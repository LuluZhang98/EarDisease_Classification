# -*- coding: utf-8 -*-
"""Normal_OM_DenseNet_Inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sXft1BJ_4goI25sdGOvGP5_M_BqalGEP
"""

#import libraries
import torch
import torchvision.transforms as transforms
from PIL import Image
import torch.nn.functional as F
from torchvision.models import densenet121
import torch.nn as nn
from torchvision import models
import matplotlib.pyplot as plt

import os
import shutil


# Provide the path to the saved model file
DenseNet_model_path = './DenseNet_model.pth'

class CustomDenseNet121(nn.Module):
    def __init__(self, num_classes=2):
        super(CustomDenseNet121, self).__init__()
        self.model = densenet121(pretrained=True)
        num_features = self.model.classifier.in_features
        self.model.classifier = nn.Linear(num_features, num_classes)

    def forward(self, x):
        x = self.model(x)
        return x


# Create an instance of the model and move it to the device
DenseNet_model = CustomDenseNet121(num_classes=2)

# Load the saved model state dictionary
DenseNet_model.load_state_dict(torch.load(DenseNet_model_path, map_location = 'cpu'))
DenseNet_model.eval()


import matplotlib.pyplot as plt

def densenet_predict(img_path):

    # Load the image
    image = Image.open(img_path).convert('RGB')

    # Define the transformations for inference
    transform = transforms.Compose([
        transforms.CenterCrop(1500),
        transforms.Resize((244, 244)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.3850, 0.3613, 0.3489], std=[0.3558, 0.3377, 0.3284])
    ])

    # Apply the same preprocessing steps as during training
    image_transformed = transform(image)

    # Add a batch dimension to the image tensor
    image_tensor = image_transformed.unsqueeze(0)

    # Forward pass through the model
    with torch.no_grad():
        DenseNet_model.eval()  # Set the model to evaluation mode
        output = DenseNet_model(image_tensor)

    # Apply softmax to the output tensor
    probabilities = F.softmax(output, dim=1)

    # Get the predicted class and its probability confidence
    predicted_prob, predicted_class = torch.max(probabilities, dim=1)

    # Convert the predicted class and its probability confidence to Python scalars
    predicted_prob = predicted_prob.item()
    predicted_class = predicted_class.item()

    # Define the class labels
    class_labels = ['NORMAL', 'Otitis Media']

    # Print the predicted class and its probability confidence with color
    predicted_text = '\033[94m{}\033[0m'.format(class_labels[predicted_class])
    confidence_text = '\033[94m{:.2f}%\033[0m'.format(predicted_prob * 100)
    # Print the predicted class and its probability confidence with color
    print('Possibly',predicted_text, 'with', confidence_text,'likelihood.' ' Not for diagnosis, always consult a doctor')

    # # Display the original image
    # plt.imshow(image)
    # plt.axis('off')
    # plt.show()

    return class_labels[predicted_class], format(predicted_prob * 100, '.2f')